# Interacting with Multimodal models in GitHub Models and Microsoft Copilot

This repository is for the Global AI Bootcamp 2025 workshop: *Interacting with Multimodal models in GitHub Models and Microsoft Copilot*

![session banner](./Images/banner.jpg)

## Session Description

This workshop is designed to give you a hands-on introduction to the core concepts and best practices for interacting with OpenAI models in GitHub Models portal. We will be running the workshop using [GitHub Models](https://github.com/marketplace/models) and [Microsoft Copilot](https://copilot.microsoft.com/).

### Abstract
Innovate with Azure OpenAI's GPT-4o multimodal model in this hands-on experience in GitHub Models and Microsoft Copilot. Learn the core concepts and best practices to effectively generate with text, sound, and images using GPT-4o-mini and Copilot. 

### Duration
45 - 60 minutes

### [Slide Deck](TBD)

## Learning Outcomes
* Understand how Large Language Models work, including what tokens are​.
* Explore Prompt Engineering techniques and best practices​
* Understand how models apply existing knowledge​

## Technology Used
* GitHub Models
* Microsoft Copilot